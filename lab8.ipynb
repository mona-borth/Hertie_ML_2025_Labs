{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 8\n",
    "## Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats\n",
    "import pymc as pm\n",
    "import arviz as az\n",
    "import xarray as xr\n",
    "\n",
    "from pymc import Model, Normal, sample, HalfNormal, StudentT, HalfStudentT\n",
    "\n",
    "# I had errors when installing pymc on Windows regardign g++ missing, resolved by running `conda install m2w64-toolchain` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Billard Ball Example\n",
    "We are going to start by implementing the code for the billard ball example we saw in the Lecture this week.\n",
    "\n",
    "As a reminder: Imagine a billiard table where a red ball is placed at a random position  along a 1D axis (between 0 and 1). A set of white balls is randomly placed, and we observe the number of white balls that landed to the left of the red ball. Given this observation, we want to infer the position of the red ball  using Bayesian analysis.\n",
    "\n",
    "### Data Generation\n",
    "\n",
    "First lets generate the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 123\n",
    "rng = np.random.RandomState(RANDOM_SEED)\n",
    "\n",
    "# True position of red ball\n",
    "theta_true = rng.uniform(0, 1)\n",
    "\n",
    "# Number of white balls observed\n",
    "N = 15  # Total white balls\n",
    "data = rng.binomial(1, theta_true, N)\n",
    "X = np.sum(data)  # Count of white balls to the left of the red ball"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prior Distribution\n",
    "\n",
    "Here we assume a Beta prior: $\\theta \\sim \\text{Beta}(1, 1)$. This is called the uniform prior, in theory it is designed to be maximally uninformative (but in practice this is not always the case, especially in low data settings)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_grid = np.linspace(0, 1, 1000) # Create a grid of theta values (possible positions of the red ball)\n",
    "a0, b0 = 1, 1  # Beta prior parameters\n",
    "prior_pdf = scipy.stats.beta.pdf(theta_grid, a=a0, b=b0)\n",
    "\n",
    "plt.plot(theta_grid, prior_pdf, label=\"Beta(1,1)\", color=\"red\")\n",
    "plt.fill_between(theta_grid, prior_pdf, alpha=0.3, color=\"red\")\n",
    "plt.title(\"Prior Distribution\")\n",
    "plt.xlabel(\"Theta\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Likelihood\n",
    "We can use the binomial likelihood function to calculate the likelihood of observing X given N and theta by considering each ball to the left of the red ball as a success and each ball to the right as a failure. The probability of any given ball falling either side of the red ball, theta, is then also the position of the ball. I.e. if the value was 0.5 then there would be a 50% porbability of a white ball being to it's left.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood_values = scipy.stats.binom.pmf(X, N, theta_grid)\n",
    "\n",
    "plt.plot(theta_grid, likelihood_values, label=\"Likelihood\", color=\"blue\")\n",
    "plt.axvline(X / N, color=\"black\", linestyle=\"--\", label=f\"MLE = {X / N:.4f}\")\n",
    "plt.title(\"Likelihood Function\")\n",
    "plt.xlabel(\"Theta\")\n",
    "plt.ylabel(\"Likelihood\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analytical Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we caclulate the analytic solution as we saw in the slides, this works because we have a conjugate prior. The resulting posterior is also a beta distribution, with the parameters updated based on the observed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_post = a0 + X\n",
    "b_post = b0 + N - X\n",
    "posterior_pdf = scipy.stats.beta.pdf(theta_grid, a_post, b_post)\n",
    "\n",
    "plt.plot(theta_grid, posterior_pdf, label=f\"Beta({a_post},{b_post})\", color=\"red\")\n",
    "plt.fill_between(theta_grid, posterior_pdf, alpha=0.3, color=\"red\")\n",
    "plt.axvline((a_post - 1) / (a_post + b_post - 2), color=\"black\", linestyle=\"--\", label=\"MAP\")\n",
    "plt.title(\"Posterior Distribution\")\n",
    "plt.xlabel(\"Theta\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian Inference with MCMC\n",
    "\n",
    "Now we switch to PyMC, a Python library for probabilistic programming and Bayesian inference. This library allows us to define probabilistic models and perform inference using Markov Chain Monte Carlo (MCMC) methods.\n",
    "\n",
    "\n",
    "#### 1. Model Specification in PyMC\n",
    "To use PyMC we need to define a model. This means specifying a Likelihood function as well as a prior distribution for the parameters we want to estimate. In this case, we will use a Beta distribution as the prior for theta, and a Bernoulli distribution as the likelihood function as above.\n",
    "In PyMC3 we specify the model using a context manager, defining the priors and likelihood within a `with` block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "billiard_model = pm.Model()\n",
    "with billiard_model:\n",
    "    # Define Prior\n",
    "    theta = pm.Beta(\"theta\", alpha=a0, beta=b0)\n",
    "    # Define Likelihood\n",
    "    x = pm.Bernoulli(\"x\", p=theta, observed=np.concatenate([[1] * X, [0] * (N - X)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Sampling from the Posterior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can sample from the posterior distribution. The number of draws is an important parameter, as we want to make sure that convergence is reached, however more draws increases runtime and memory usage. You can check convergence diagnostics to ensure you have enough draws."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with billiard_model:\n",
    "    posterior_sample = pm.sample(draws=1000, return_inferencedata=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Visualizing MCMC Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpreting a Trace Plot\n",
    "\n",
    "A **trace plot** is a key diagnostic tool in Bayesian analysis to check whether an MCMC sampler has converged. It shows how the sampled values of a parameter change over iterations. We visualize the trace plot and extract summaries using ArviZ. \n",
    "\n",
    "*Characteristics of a Good Trace Plot*\n",
    "- **Stationarity:** The chain fluctuates around a consistent mean and does not drift in one direction.\n",
    "- **Good Mixing:** The samples move up and down rapidly without long periods of high or low values.\n",
    "- **Low Autocorrelation:** The samples should appear random rather than highly correlated.\n",
    "\n",
    "*Signs of Problems*\n",
    "- **Drifting / Non-Stationarity:** If the chain trends in one direction, it has not converged yet. Consider increasing burn-in or adjusting the sampling parameters.\n",
    "- **Poor Mixing:** If the values get \"stuck\" for many iterations before jumping, the sampler might not be exploring the posterior well.\n",
    "- **Differences Between Chains:** If multiple chains do not overlap well, this indicates that the model might not have converged.\n",
    "\n",
    "*Multiple Chains and Convergence Check*\n",
    "- When running **multiple MCMC chains**, they should all look similar.\n",
    "- The **R-hat statistic** should be close to 1.00 (values above 1.1 suggest convergence issues)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(posterior_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.summary(posterior_sample, round_to=2, hdi_prob=0.90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also extract the samples to a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_samples = az.extract(\n",
    "    posterior_sample, group=\"posterior\", combined=False, var_names=[\"theta\"]\n",
    ").to_numpy()\n",
    "# The array has dimension 4x1000, with the 4 chains and 1000 simulations per chain\n",
    "print(theta_samples.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Plotting posterior distribution\n",
    "\n",
    "Here we plot the posterior distribution of theta with the theoretical posterior from above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(\n",
    "    theta_samples.flatten(), bins=30, density=True, alpha=0.5, label=\"Posterior Samples\"\n",
    ")\n",
    "plt.plot(\n",
    "    theta_grid, posterior_pdf, label=f\"Beta({a_post},{b_post})\", color=\"red\"\n",
    ")\n",
    "plt.fill_between(\n",
    "    theta_grid, posterior_pdf, alpha=0.3, color=\"red\", label=\"Theoretical Posterior\"\n",
    ")\n",
    "plt.axvline(\n",
    "    np.mean(theta_samples), color=\"black\", linestyle=\"--\", label=\"Analytic Posterior Mean\"\n",
    ")\n",
    "plt.axvline(\n",
    "    (a_post - 1) / (a_post + b_post - 2),color=\"black\",linestyle=\":\",label=\" Analytic Posterior MAP\",\n",
    ")\n",
    "plt.title(\"Posterior Distribution\")\n",
    "plt.xlabel(\"Theta\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Posterior Predictive Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The posterior predictive distribution represents our uncertainty about future observations, given the data we have already seen and the inferred posterior distribution of the model parameters. Essentially, it tells us what future data might look like if we were to repeat the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we simulate the posterior predictive distribution\n",
    "with billiard_model:\n",
    "    posterior_predictive = pm.sample_posterior_predictive(trace=posterior_samples, extend_inferencedata=True)\n",
    "\n",
    "# Then we extract the posterior predictive samples\n",
    "x_new_simulate = az.extract(\n",
    "    posterior_samples, group=\"posterior_predictive\", combined=False\n",
    ")['x'].to_numpy()\n",
    "# The array has dimension 4x10_000xN (4 chains, 1000 simulations per chain, N observations)\n",
    "print(x_new_simulate.shape)\n",
    "\n",
    "# Now we can visualize the posterior predictive distribution\n",
    "p_posterior_pred = x_new_simulate.mean()\n",
    "fig, ax = plt.subplots(figsize=(6, 3))\n",
    "ax.bar(\n",
    "    [\"Left (1)\", \"Right (0)\"],\n",
    "    [p_posterior_pred, 1 - p_posterior_pred],\n",
    "    color=\"skyblue\",\n",
    "    alpha=0.7,\n",
    ")\n",
    "ax.set_title(\"Posterior Predictive Distribution\")\n",
    "ax.set_ylabel(\"Probability\")\n",
    "ax.set_ylim(0, 1)\n",
    "for i, v in enumerate([p_posterior_pred, 1 - p_posterior_pred]):\n",
    "    ax.text(i, v + 0.03, f\"{v:.2f}\", ha=\"center\", fontweight=\"bold\")\n",
    "ax.grid(True, axis=\"y\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression in Bayesian form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to work through another simulated example, but this time for a linear regression problem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we generate the data again, this time with a linear model with true intercept 1 and slope 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 200\n",
    "true_intercept = 1\n",
    "true_slope = 2\n",
    "\n",
    "x = np.linspace(0, 1, size)\n",
    "# y = a + b*x\n",
    "true_regression_line = true_intercept + true_slope * x\n",
    "# add noise\n",
    "y = true_regression_line + rng.normal(scale=0.5, size=size)\n",
    "\n",
    "data = pd.DataFrame({\"x\": x, \"y\": y})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(7, 7))\n",
    "ax = fig.add_subplot(111, xlabel=\"x\", ylabel=\"y\", title=\"Generated data and underlying model\")\n",
    "ax.plot(x, y, \"x\", label=\"sampled data\")\n",
    "ax.plot(x, true_regression_line, label=\"true regression line\", lw=2.0)\n",
    "plt.legend(loc=0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyMC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we did we will have to define a model with a likelihood and prior distribution. However lets now consider our flat (uninformative) prior from above. Does this still make sense in this context? How would we bound it?\n",
    "\n",
    "Instead we usually want to set a weakly informative prior, which incorporate engineering assumptions into the prior, as well as performing normalisation.\n",
    "\n",
    "We could also set an informative prior, where we encode domain expertise into a probability distribution. This is the ideal type in Bayesian statistics, but in practice can be difficult as it is not always tractable to convert expertise into probability distributions nor is there always prior information available for all our parameters.\n",
    "\n",
    "Below is the code for two of the most most common distributions used for priors, the Normal and student-t distribution. Play around with their parameters to get an intuition of how they work. (The Cauchy distribution, which is also common in cases where we want a distribution with thicker tales is just a special case of student t where degrees of freedom (`df`) is 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normal and Student-T Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal1_params = {\"loc\": 0, \"scale\": 1}\n",
    "normal2_params = {\"loc\": 0, \"scale\": 2}\n",
    "t1_params = {\"df\": 3, \"loc\": 0, \"scale\": 1}\n",
    "t2_params = {\"df\": 10, \"loc\": 0, \"scale\": 1}\n",
    "\n",
    "x = np.linspace(-5, 5, 100)\n",
    "y_normal = scipy.stats.norm.pdf(x, **normal1_params)\n",
    "y_normal_2 = scipy.stats.norm.pdf(x, **normal2_params)\n",
    "y_t = scipy.stats.t.pdf(x, **t1_params)\n",
    "y_t_2 = scipy.stats.t.pdf(x, **t2_params)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(x, y_normal, label=f\"Normal, loc={normal1_params['loc']}, scale={normal1_params['scale']}\")\n",
    "plt.plot(x, y_normal_2, label=f\"Normal, loc={normal2_params['loc']}, scale={normal2_params['scale']}\")\n",
    "plt.plot(x, y_t, label=f\"Student's t, df={t1_params['df']}, loc={t1_params['loc']}, scale={t1_params['scale']}\")\n",
    "plt.plot(x, y_t_2, label=f\"Student's t, df={t2_params['df']}, loc={t2_params['loc']}, scale={t2_params['scale']}\")\n",
    "plt.title(\"Normal and Student's t Distributions\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now define our model as we did above, setting a prior for the intercept, slope and sigma.\n",
    "\n",
    "Hint: As sigma cannot be negative, we must use 'Half' distributions, e.g. HalfNormal, HalfStudentT, HalfCauchy. These are the same as the other distributions but cut off at 0 so that they do not go negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model = pm.Model()\n",
    "with linear_model:\n",
    "    # Define Priors\n",
    "    \n",
    "\n",
    "    # Define Likelihood\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now sample 3000 draws from the posterior distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use the summary and the trace plots to evaluate whether you have reached convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And sample from the posterior predictive distribution, saving the samples as `posterior_predictive`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, this code visualises our model. As our estimates are now probabilistic we have a range of best fitting regression lines, not just one. A posterior predictive plot takes multiple samples from the posterior (intercepts and slopes) and plots a regression line for each of them. We can manually generate these regression lines using the posterior samples directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idata.posterior[\"y_model\"] = idata.posterior[\"Intercept\"] + idata.posterior[\"Slope\"] * xr.DataArray(x)\n",
    "\n",
    "_, ax = plt.subplots(figsize=(7, 7))\n",
    "az.plot_lm(idata=idata, y=\"y\", num_samples=100, axes=ax, y_model=\"y_model\")\n",
    "ax.set_title(\"Posterior predictive regression lines\")\n",
    "ax.set_xlabel(\"x\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus:\n",
    "Apply this Bayesian Framework for Regression to a real world Dataset we have considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
