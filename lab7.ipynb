{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 7\n",
    "## Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy\n",
    "from numpy.typing import ArrayLike\n",
    "from sklearn.linear_model import LinearRegression, QuantileRegressor\n",
    "from sklearn.utils import resample\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ames Housing Dataset\n",
    "\n",
    "The Ames Housing Dataset is a widely used dataset for regression modeling, particularly in real estate price prediction. It contains over 2,900 home sales from Ames, Iowa in the period of 2006â€“2010. It also includes 79 explanatory variables describing house features such as lot size, year built and quality measures.\n",
    "\n",
    "This dataset is used in a  classic Kaggle data challenge, so if you get particularly good predictions you can sign up and submit them here:\n",
    "https://www.kaggle.com/competitions/house-prices-advanced-regression-techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv(\"AmesHousing.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start we are only going to look at one of the most important predictors in the dataset, the Living Area of the house, and see how well we can use it to predict Sale Price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select relevant columns\n",
    "features = [\"GrLivArea\"]  # Living area\n",
    "target = \"SalePrice\"\n",
    "df_simplified = df[features + [target]].dropna()\n",
    "\n",
    "# Log-transform the target to reduce the skewness\n",
    "df_simplified[target] = np.log(df_simplified[target])\n",
    "\n",
    "# Remove outliers as they can be quite troublesome in this dataset\n",
    "df_simplified = df_simplified[df_simplified[\"GrLivArea\"] < 4000]\n",
    "\n",
    "# Split data into train and test with an 80/20 split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_simplified[features], df_simplified[target], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First thing we want to do is to plot the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=X_train[\"GrLivArea\"], y=y_train)\n",
    "plt.xlabel(\"Living Area (sqft)\")\n",
    "plt.ylabel(\"Log Sale Price\")\n",
    "plt.title(\"Living Area vs. Sale Price\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will calulate the theoretical confidence and prediction intervals for the linear regression model using the formulae we derived in the lecture. I have left some parts for you to fill in. For the rest try think about how and why we do them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear model\n",
    "linear_model = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "# Theoretical variance of the estimator\n",
    "theta_hat = np.array([linear_model.intercept_, linear_model.coef_[0]])\n",
    "y_pred = linear_model.predict(X_train)\n",
    "sigma_hat = # Fill in the formula for the estimated standard deviation of the residuals\n",
    "X = np.column_stack((np.ones(len(X_train)), X_train))\n",
    "theta_covar_matrix = # Fill in the formula for the covariance of beta_hat\n",
    "\n",
    "# Create prediction grid\n",
    "x_pred = np.linspace(0, 4000, 100)\n",
    "X_pred = np.column_stack((np.ones(len(x_pred)), x_pred))\n",
    "\n",
    "# Compute prediction mean and standard error\n",
    "y_pred_mean = X_pred @ theta_hat\n",
    "pred_var = np.diag(X_pred @ theta_covar_matrix @ X_pred.T)\n",
    "pred_std = np.sqrt(pred_var + sigma_hat)\n",
    "\n",
    "# Plot the results\n",
    "fig, axs = plt.subplots(1, 1, figsize=(8, 6))\n",
    "# Plot data points\n",
    "axs.scatter(X[:, 1], y_train, color=\"blue\", alpha=0.5, label=\"Data\")\n",
    "# Plot regression line\n",
    "axs.plot(x_pred, y_pred_mean, \"r-\", label=\"Fitted line\")\n",
    "# Plot prediction intervals\n",
    "axs.fill_between(\n",
    "    x_pred,\n",
    "    y_pred_mean - 1.96 * pred_std,\n",
    "    y_pred_mean + 1.96 * pred_std,\n",
    "    color=\"blue\",\n",
    "    alpha=0.1,\n",
    "    label=\"95% Predictive Interval\",\n",
    ")\n",
    "# Plot confidence intervals\n",
    "axs.fill_between(\n",
    "    x_pred,\n",
    "    y_pred_mean - 1.96 * np.sqrt(pred_var),\n",
    "    y_pred_mean + 1.96 * np.sqrt(pred_var),\n",
    "    color=\"red\",\n",
    "    alpha=0.3,\n",
    "    label=\"95% CI for mean\",\n",
    ")\n",
    "axs.set_xlabel(\"X\")\n",
    "axs.set_ylabel(\"Y\")\n",
    "axs.set_title(\"Linear Regression with Confidence and Prediction Intervals\")\n",
    "axs.legend()\n",
    "axs.grid(True, alpha=0.3)\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrap\n",
    "Now we will compute the bootstrap confidence intervals for the coefficients, this is done by resampling the data with replacement and fitting the model again. This means we don't have to assume the normality of the coefficients but can still get an estimate of the uncertainty. The code for this is in the slides, see if you can extend the code from the slides to also make predictions across a range of reasonable values for GrLivArea.\n",
    "\n",
    "Hint: A useful line of code for this is `X_pred = pd.DataFrame({\"GrLivArea\": np.linspace(0, 4000, 100)})` which defines a linear space over the range of GrLivArea, which we can then input into the model the same as we would new test values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we plot the Bootstap and theoretical intervals in two different ways. In what ways do they differ? What does this tell us about our data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap_coefs = np.array(bootstrap_coefs)\n",
    "bootstrap_predictions = np.array(bootstrap_predictions)\n",
    "\n",
    "# Compute bootstrap intervals\n",
    "pred_intervals = np.percentile(bootstrap_predictions, [2.5, 97.5], axis=0)\n",
    "\n",
    "# Plot bootstrap\n",
    "fig, axs = plt.subplots(1, 1, figsize=(12, 8))\n",
    "# Plot data points\n",
    "axs.scatter(X[:, 1], y, color=\"blue\", alpha=0.5, label=\"Data\")\n",
    "# Plot regression line\n",
    "axs.plot(x_pred, y_pred_mean, \"r-\", label=\"Fitted line\")\n",
    "# Plot theoretical confidence intervals\n",
    "axs.fill_between(\n",
    "    x_pred,\n",
    "    y_pred_mean - 1.96 * np.sqrt(pred_var),\n",
    "    y_pred_mean + 1.96 * np.sqrt(pred_var),\n",
    "    color=\"red\",\n",
    "    alpha=0.2,\n",
    "    label=\"Theoretical 95% CI\",\n",
    ")\n",
    "axs.fill_between(\n",
    "    x_pred,\n",
    "    pred_intervals[0],\n",
    "    pred_intervals[1],\n",
    "    color=\"blue\",\n",
    "    alpha=0.2,\n",
    "    label=\"Bootstrap 95% CI\",\n",
    ")\n",
    "axs.set_xlabel(\"X\")\n",
    "axs.set_ylabel(\"Y\")\n",
    "axs.set_title(\"Linear Regression with Theoretical and Bootstrap Intervals\")\n",
    "axs.legend()\n",
    "axs.grid(True, alpha=0.3)\n",
    "axs.set_xlim([0, 4000])\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_std = np.sqrt(theta_covar_matrix[1, 1])\n",
    "beta_hat = theta_hat[1]\n",
    "beta_range = np.linspace(beta_hat - 3 * beta_std, beta_hat + 3 * beta_std, 100)\n",
    "beta_dist = scipy.stats.norm.pdf(beta_range, beta_hat, beta_std)\n",
    "plt.plot(beta_range, beta_dist, label=\"Theoretical\")\n",
    "plt.hist(bootstrap_coefs, density=True, alpha=0.3, label=\"Bootstrap\", bins=50)\n",
    "plt.xlabel(\"Beta\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.title(\"Bootstrap Distribution of Beta\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantile Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will implement the quantile regression on the same data to get a better sense of the variability. For the moment we will use scikit-learn for the implementation, but if you want an even more flexible implementation you can see the example code from Chris on moodle which uses jax instead. Do you think this is a good model? Try changing the quantiles to see the results in the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantiles = [0.1, 0.5, 0.9]\n",
    "q_models = {q: QuantileRegressor(quantile=q, alpha=0) for q in quantiles}\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "for q, model in q_models.items():\n",
    "    model.fit(X_train[\"GrLivArea\"].values.reshape(-1, 1), y_train)\n",
    "    y_pred = model.predict(X_test[\"GrLivArea\"].values.reshape(-1, 1))\n",
    "    plt.scatter(X_test[\"GrLivArea\"], y_pred, label=f\"{int(q * 100)}th Percentile\")\n",
    "plt.scatter(X_test[\"GrLivArea\"], y_test, color=\"black\", alpha=0.5, label=\"True Values\") \n",
    "plt.xlabel(\"Living Area\")\n",
    "plt.ylabel(\"Log Sale Price\")\n",
    "plt.legend()\n",
    "plt.title(\"Quantile Regression - Predicting Different Percentiles\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantile Regression for Tree-Based Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to fit a fully flexible Tree-based quantile model to the data. To do so we need to do quite a few preprocessing steps. Make sure everything here makes sense to you. This is only one potential way to clean this data. When you get to the final step feel free to change any of these choices to try improve the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset again for clarity\n",
    "df = pd.read_csv(\"AmesHousing.csv\")\n",
    "\n",
    "#Some columns have a lot of missing values, so we will drop them\n",
    "cols_to_drop = ['FireplaceQu', 'PoolQC', 'Fence', 'MiscFeature', 'Alley', 'MasVnrType']\n",
    "df = df.drop(columns=cols_to_drop)\n",
    "\n",
    "# log transform the target\n",
    "target = \"SalePrice\"\n",
    "df[target] = np.log(df[target])\n",
    "\n",
    "# Remove outliers\n",
    "df = df[df[\"GrLivArea\"] < 4000] \n",
    "\n",
    "categorical_features = df.select_dtypes(include=['object', 'category']).columns\n",
    "numerical_features = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "numerical_features = numerical_features.drop(target)\n",
    "\n",
    "#Train-test split\n",
    "X_train_full, X_test_full, y_train, y_test = train_test_split(df.drop(columns=[target]), df[target], test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocess the data by one-hot encoding the categorical features and imputing the missing values in the numerical features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output= False), categorical_features),\n",
    "        ('num', SimpleImputer(strategy='mean'), numerical_features)\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "X_train_full = preprocessor.fit_transform(X_train_full)\n",
    "X_test_full = preprocessor.transform(X_test_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting the Model\n",
    "\n",
    "Now we fit the model with the same quantiles as before and a set of parameters I chose fairly arbitrarily. See if you can fill the fitting process in from the code in the lecture slides.\n",
    "\n",
    "Hint: I would add `verbosity=-1` to any LightBGM model I run to prevent loads of warnings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantile_alphas = [0.1, 0.5, 0.9]\n",
    "\n",
    "lgb_params = {\n",
    "    'n_jobs': 1,\n",
    "    'max_depth': 4,\n",
    "    'min_data_in_leaf': 10,\n",
    "    'subsample': 0.9,\n",
    "    'n_estimators': 100,\n",
    "    'learning_rate': 0.1,\n",
    "    'colsample_bytree': 0.9\n",
    "}\n",
    "\n",
    "## Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets compute the prediction for the different bounds of the test data. I have provided the code for this as it is a good example of looping over models themselves, make sure you understand it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantile_predictions = {}\n",
    "for quantile_alpha, model in lgb_quantile_alphas.items():\n",
    "    quantile_predictions[quantile_alpha] = model.predict(X_test_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the predictions and analyse to see how well we think our model is doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.scatter(y_test, quantile_predictions[0.1], color='red', alpha=0.5, label='Predictions (0.1)')\n",
    "plt.scatter(y_test, quantile_predictions[0.5], color='blue', alpha=0.5, label='Predictions (0.5)')\n",
    "plt.scatter(y_test, quantile_predictions[0.9], color='green', alpha=0.5, label='Predictions (0.9)')\n",
    "plt.xlabel(\"True Values\")\n",
    "plt.ylabel(\"Predictions\")\n",
    "plt.title(\"Quantile Predictions\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I also selected a smaller subset of the test data, show the predictions for the 0.1, 0.5, and 0.9 quantiles and the true values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 50\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(range(n_samples), y_test[:n_samples], color='black', alpha=0.5, label='True Values')\n",
    "plt.scatter(range(n_samples), quantile_predictions[0.5][:n_samples], color='blue', alpha=0.5, label='Predictions (0.5)')\n",
    "plt.scatter(range(n_samples), quantile_predictions[0.1][:n_samples], color='red', alpha=0.5, label='Predictions (0.1)')\n",
    "plt.scatter(range(n_samples), quantile_predictions[0.9][:n_samples], color='green', alpha=0.5, label='Predictions (0.9)')\n",
    "plt.xlabel(\"Sample Index\")\n",
    "plt.ylabel(\"Values\")\n",
    "plt.title(\"Quantile Predictions for a Subset of Test Data\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pinball Loss / Quantile Loss\n",
    "As we are no longer fitting a mean-based model, it does not make sense to evaluate models with the MSE, instead we use the quantile loss, which can also be called the Pinball Loss. The code below calculates the pinball loss for each of our quantiles.\n",
    "\n",
    "For a given quantile $\\tau$ and a prediction $\\hat{y}$ for an actual value $y$, the pinball loss is calculated as:\n",
    "\n",
    "$$\n",
    "L_{\\tau}(y, \\hat{y}) =\n",
    "\\begin{cases}\n",
    "\\tau(y - \\hat{y}) & \\text{if } y \\geq \\hat{y} \\quad (\\text{underestimation penalty})\\\\\n",
    "(1 - \\tau)(\\hat{y} - y) & \\text{if } y < \\hat{y} \\quad (\\text{overestimation penalty})\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "- If $y$ is **greater than** $\\hat{y}$, the loss is proportional to **$\\tau$** times the error.\n",
    "- If $y$ is **less than** $\\hat{y}$, the loss is proportional to **$(1 - \\tau)$** times the error.\n",
    "- This means **over-predicting is penalized less than under-predicting for high quantiles** (e.g., $\\tau=0.9$) and vice versa for low quantiles ($\\tau=0.1$).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinball_losses = {}\n",
    "\n",
    "for quantile_alpha in quantile_alphas:\n",
    "    pinball_losses[quantile_alpha] = np.mean(np.maximum(quantile_predictions[quantile_alpha] - y_test, 0) * quantile_alpha + np.maximum(y_test - quantile_predictions[quantile_alpha], 0) * (1 - quantile_alpha))\n",
    "    \n",
    "pinball_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets see what proportion of the true values fall below the 0.1 and 0.9 quantile predictions? Do you think our model is doing well?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "within_quantiles = np.mean((quantile_predictions[0.1] <= y_test) & (y_test <= quantile_predictions[0.9]))\n",
    "\n",
    "print(f\"Proportion of true values within the 0.1 and 0.9 quantile predictions: {within_quantiles:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Task:\n",
    "Think about how you could further finetune this model and implement it. See if you can improve on the metrics above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
